{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Assignment: PCA Implementation\nObjective:\nThe objective of this assignment is to implement PCA on a given dataset and analyse the results.\n\nDeliverables:\nJupyter notebook containing the code for the PCA implementation.\nA report summarising the results of PCA and clustering analysis.\nScatter plot showing the results of PCA.\nA table showing the performance metrics for the clustering algorithm.\n\nAdditional Information:\nYou can use the python programming language.\nYou can use any other machine learning libraries or tools as necessary.\nYou can use any visualisation libraries or tools as necessary.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Steps to Implement PCA and Clustering Analysis\n1. Import Required Libraries\nYou will need libraries like numpy, pandas, matplotlib, seaborn, sklearn, etc., to perform the analysis.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import silhouette_score, accuracy_score\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "2. Load the Dataset\nMake sure you have a dataset to apply PCA and clustering. If you don't have one, you can use a popular dataset such as the Iris dataset from sklearn.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Example: Load the Iris dataset\nfrom sklearn.datasets import load_iris\ndata = load_iris()\nX = data.data  # Features\ny = data.target  # Labels\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "#Alternatively, if you're working with your custom dataset, load it using:\n# Custom Dataset\ndata = pd.read_csv('your_dataset.csv')\nX = data.drop('target_column', axis=1)\ny = data['target_column']",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "3. Standardize the Data\nPCA works best when the features are standardized (i.e., scaled to have zero mean and unit variance).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "scaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "4. Apply PCA\nPerform PCA to reduce the dataset's dimensions. For example, if you want to reduce the data to 2 components for visualization:",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "pca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "5. Visualize the PCA Results\nPlot a scatter plot to visualize the data after reducing its dimensions.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "plt.figure(figsize=(8, 6))\nsns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, palette='viridis')\nplt.title('PCA - 2D Projection')\nplt.xlabel('Principal Component 1')\nplt.ylabel('Principal Component 2')\nplt.show()",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "6. Clustering with K-Means\nAfter performing PCA, you can apply a clustering algorithm such as K-Means to cluster the data points",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Apply KMeans clustering\nkmeans = KMeans(n_clusters=3, random_state=42)  # Adjust n_clusters based on your data\nclusters = kmeans.fit_predict(X_pca)\n\n# Add cluster labels to the PCA results\nX_pca_df = pd.DataFrame(X_pca, columns=['PC1', 'PC2'])\nX_pca_df['Cluster'] = clusters\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "7. Performance Metrics for Clustering\nEvaluate the performance of your clustering model. For KMeans, you can use metrics like silhouette score, adjusted rand score, or accuracy (if you have ground truth labels).",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Silhouette score\nsil_score = silhouette_score(X_pca, clusters)\nprint(f'Silhouette Score: {sil_score:.3f}')\n\n# If you have ground truth labels (y), calculate the accuracy\naccuracy = accuracy_score(y, clusters)\nprint(f'Clustering Accuracy: {accuracy:.3f}')",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "8. Create a Performance Metrics Table\nYou can create a simple table to summarize the performance metrics.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Performance metrics table\nmetrics = {\n    'Silhouette Score': [sil_score],\n    'Accuracy': [accuracy]\n}\nmetrics_df = pd.DataFrame(metrics)\nmetrics_df\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "9. Final Report Summary\nThe final step will involve summarizing the results of PCA and clustering in a markdown cell or a report.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "# PCA and Clustering Analysis\n\n## Objective:\nThe objective of this assignment is to implement Principal Component Analysis (PCA) on the dataset and perform clustering using KMeans. We will visualize the results, assess the clustering performance, and discuss the findings.\n\n## 1. Data Loading and Preprocessing\n- We begin by loading the dataset and performing necessary preprocessing steps such as standardizing the data.\n\n## 2. PCA Implementation\n- PCA is applied to reduce the dataset's dimensions to 2, enabling us to visualize the data in two dimensions.\n\n## 3. Visualizing PCA Results\n- We plot the 2D projection of the dataset after PCA.\n\n## 4. Clustering Analysis\n- KMeans clustering is performed on the PCA-reduced data, and the clustering results are visualized.\n\n## 5. Performance Metrics\n- We evaluate the clustering performance using silhouette score and clustering accuracy.\n\n### PCA and Clustering Visualizations\n\n![PCA 2D Plot](link_to_image)\n\n## Performance Metrics\n\n| Metric            | Value     |\n|-------------------|-----------|\n| Silhouette Score  | X.XXX     |\n| Clustering Accuracy | X.XXX   |\n\n## Conclusion:\nBased on the PCA visualization and clustering performance, we can conclude that the model's performance is [good/fair/poor] in this case, with a silhouette score of X.XXX and an accuracy of X.XXX.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Example Output (Hypothetical)\nPCA Scatter Plot: The plot will show how the data points are spread along the first two principal components. Different colors represent different true classes (if available).\n\nClustering Performance Table:\n\nMetric\tValue\nSilhouette Score\t0.54\nClustering Accuracy\t0.93",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}