{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "955a7bca-3612-417c-a54f-ece86de22b06",
   "metadata": {},
   "source": [
    "Q1. What is data encoding? How is it useful in data science?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4cb618-7471-4247-b146-3b02d92891e3",
   "metadata": {},
   "source": [
    "Data encoding in data science is the process of converting data from one format to another, typically to prepare it for analysis by machine learning algorithms. It acts as a translator between human-understandable data and the numerical language that computers use.\n",
    "\n",
    "There are two main reasons why data encoding is useful in data science:\n",
    "\n",
    "Makes data usable for algorithms: Most machine learning algorithms can only process numerical data. Encoding transforms non-numerical data, like text or categorical variables (e.g., hair color: blonde, brown, black), into a format that algorithms can understand and work with.\n",
    "\n",
    "Improves data analysis: Encoding can help identify patterns and relationships in the data that might be hidden in its original format. For instance, encoding customer zip codes into geographic coordinates allows for analysis on a map, revealing trends based on location.\n",
    "\n",
    "In essence, data encoding bridges the gap between raw data and actionable insights by making it suitable for computational analysis."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4351ce3a-adf4-4933-ac8f-08b512043f7e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f78be852-6221-4f14-82f9-1b9444e9ed39",
   "metadata": {},
   "source": [
    "Q2. What is nominal encoding? Provide an example of how you would use it in a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84ed2f26-1c89-4d6e-82ec-e4fddbd731f1",
   "metadata": {},
   "source": [
    "Nominal encoding, also commonly referred to as one-hot encoding, is a technique specifically used for categorical data that  doesn't have any inherent order.  This means the categories are simply labels and shouldn't be interpreted as having a ranking or hierarchy.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "Identify Nominal Features: First, you identify features in your data that are categorical and nominal. Examples include things like  customer hair color (blonde, brunette, black),  shirt size (S, M, L, XL), or  fruit type (apple, orange, banana).\n",
    "\n",
    "Create Binary Columns:  For each unique category within the nominal feature, a new binary column is created. These new columns are often called dummy variables.\n",
    "\n",
    "Assign Values (0 or 1): Each data point in the original feature is then assigned a value of 1 in the corresponding new column if it belongs to that category, and 0 otherwise.\n",
    "\n",
    "This essentially creates a new representation of the data where each category is broken down into its own presence/absence indicator.\n",
    "\n",
    "Real-world Example: Analyzing Online Shopping Trends\n",
    "\n",
    "Imagine you're analyzing customer purchase data from an online clothing store. One feature might be the department where a particular item was purchased (e.g., Men's, Women's, Kids'). This is a nominal feature because there's no inherent order between the departments.\n",
    "\n",
    "Using nominal encoding, you would create three new binary columns: \"Men's_Dept,\" \"Women's_Dept,\" and \"Kids_Dept.\" Each row in the data would then be assigned a 1 in the corresponding department column if the item was purchased from that department, and 0 otherwise.\n",
    "\n",
    "This allows you to analyze purchase trends across departments more effectively. For instance, you might identify if a particular promotion had a higher impact on the Men's department or the Women's department by looking at the corresponding columns.\n",
    "\n",
    "By converting the nominal data into a format that highlights presence or absence, nominal encoding helps extract meaningful insights from categorical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e1fa55-15c3-49a3-a9ab-6259cb575612",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "247a011c-a781-4d3a-a5b5-3bf8319cf475",
   "metadata": {},
   "source": [
    "Q3. In what situations is nominal encoding preferred over one-hot encoding? Provide a practical example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebfe364-557a-4a8b-a8d5-6405ba445ea7",
   "metadata": {},
   "source": [
    "There actually isn't a practical difference between nominal encoding and one-hot encoding. They are simply two different terms used for the same data encoding technique.  Both refer to the process of creating binary dummy variables to represent categorical data with no inherent order.\n",
    "\n",
    "Some resources might use the terms interchangeably, while others might make a slight distinction where \"nominal encoding\" is the general concept and \"one-hot encoding\" is the specific method of creating binary columns with values of 1 or 0.\n",
    "\n",
    "Here's an analogy:  A car can be called a \"four-wheeled vehicle\" or a \"sedan\" depending on the level of detail. Nominal encoding and one-hot encoding are like these two terms for the same car - they both describe the same essential concept."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded1022f-3631-495b-96b7-6d735b750d66",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25984e41-0d17-4fed-b3b4-bcb3b60cde3b",
   "metadata": {},
   "source": [
    "Q4. Suppose you have a dataset containing categorical data with 5 unique values. Which encoding\n",
    "technique would you use to transform this data into a format suitable for machine learning algorithms?\n",
    "Explain why you made this choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a27b87-8660-4203-9243-67ce45e6835b",
   "metadata": {},
   "source": [
    "For a dataset containing categorical data with 5 unique values, two main encoding techniques would be suitable for machine learning algorithms:\n",
    "\n",
    "One-Hot Encoding (also known as Nominal Encoding): This is a strong choice because it effectively captures the categorical nature of the data without assuming any inherent order between the values. Each of the 5 unique values would be represented by a separate binary column, making it clear which category a data point belongs to.\n",
    "\n",
    "Label Encoding: This is another option. It assigns a unique integer (0, 1, 2, 3, 4) to each of the 5 categories. However, it's important to consider if the categories have an intrinsic order. If they don't (which is likely since there are only 5), then label encoding works well.\n",
    "\n",
    "Here's why one-hot encoding might be a better choice in this scenario:\n",
    "\n",
    "Clarity: One-hot encoding explicitly separates the categories, making it easier for the machine learning algorithm to understand the relationships between the data points and the categorical feature.\n",
    "\n",
    "Scalability: Even with 5 categories, label encoding can become cumbersome as the number of categories grows. One-hot encoding maintains a clear structure regardless of the number of categories (as long as they are nominal).\n",
    "\n",
    "Interpretability: Although one-hot encoding creates more features, the binary values (0 or 1) are easier to interpret compared to potentially arbitrary integer assignments in label encoding (especially if the category order isn't meaningful).\n",
    "\n",
    "Therefore, while both techniques can work,  one-hot encoding is generally preferred for categorical data with a moderate number of unique values (like 5) where order doesn't matter. It provides a clear, scalable, and interpretable representation for machine learning algorithms."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d3242cbc-9e61-4fbd-b1d5-09eb58ddefa2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2636dd54-5b16-4b96-86bc-5f25022beb52",
   "metadata": {},
   "source": [
    "Q5. In a machine learning project, you have a dataset with 1000 rows and 5 columns. Two of the columns\n",
    "are categorical, and the remaining three columns are numerical. If you were to use nominal encoding to\n",
    "transform the categorical data, how many new columns would be created? Show your calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050793a-8f2a-4be9-8a21-2abf8152d84c",
   "metadata": {},
   "source": [
    "Let's analyze the number of new columns created by nominal encoding for the two categorical features:\n",
    "\n",
    "Identify Number of Unique Values: We don't have specific information about how many unique values each categorical column has. Let's represent the number of unique values in the first categorical feature as F1 and the number of unique values in the second categorical feature as F2.\n",
    "\n",
    "Encoding for Each Feature: Nominal encoding creates one binary column for each unique value within a categorical feature.\n",
    "\n",
    "Total New Columns: Therefore, for the first categorical feature, F1 new columns will be created (one for each unique value). Similarly, for the second categorical feature, F2 new columns will be created.\n",
    "\n",
    "Total New Columns (Combined): To find the total number of new columns from both categorical features, we simply add the number of new columns from each:\n",
    "\n",
    "Total New Columns = F1 (new columns) + F2 (new columns)\n",
    "\n",
    "However, there's a key point to consider:\n",
    "\n",
    "The calculation assumes we treat each categorical feature independently. In practice, it's possible that some unique values might exist in both categorical features (e.g., a color category \"red\" could be present in both a clothing category and a fruit category). In such cases, the corresponding binary column for \"red\" would only be created once.\n",
    "\n",
    "Without knowing the specific details of the data and the overlap between unique values in each feature, we can't provide a definitive number of new columns.\n",
    "\n",
    "Example Scenario (without overlap):\n",
    "\n",
    "Assume F1 (unique values in first feature) = 3\n",
    "Assume F2 (unique values in second feature) = 4\n",
    "Then, Total New Columns = 3 + 4 = 7 new columns would be created.\n",
    "\n",
    "Example Scenario (with overlap):\n",
    "\n",
    "Imagine one unique value (\"blue\") exists in both categorical features.\n",
    "Let F1 = 4 (including \"blue\") and F2 = 5 (including \"blue\")\n",
    "Here, only one binary column would be created for \"blue.\" Effectively, the total new columns would be:\n",
    "\n",
    "Total New Columns = (F1 - 1) + (F2 - 1)  = (4 - 1) + (5 - 1) = 6 new columns (excluding the duplicate \"blue\" column).\n",
    "\n",
    "In conclusion:\n",
    "\n",
    "The number of new columns created by nominal encoding depends on the specific number of unique values in each categorical feature and any potential overlap between those values. It can range from F1 + F2 (without overlap) to (F1 - 1) + (F2 - 1) (with some overlap) in the worst case."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc4cdaf-8164-40a2-8a44-041307ae02dc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a86213c1-b268-43d5-a07a-48b1fdbc7d0d",
   "metadata": {},
   "source": [
    "Q6. You are working with a dataset containing information about different types of animals, including their\n",
    "species, habitat, and diet. Which encoding technique would you use to transform the categorical data into\n",
    "a format suitable for machine learning algorithms? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1916f7be-2d46-4a12-90d2-992a7e108585",
   "metadata": {},
   "source": [
    "Here's the approach to encoding categorical data in the animal dataset:\n",
    "\n",
    "Encoding Techniques:\n",
    "\n",
    "Species: This is most likely a categorical feature with no inherent order (e.g., dog, cat, elephant). Nominal encoding (one-hot encoding) would be a perfect choice. Each unique species would be represented by a separate binary column.\n",
    "\n",
    "Habitat: This could be categorical (e.g., forest, desert, ocean) or ordinal (e.g., freshwater, saltwater, terrestrial).\n",
    "\n",
    "If habitat is categorical (no order): Use nominal encoding. Similar to species, each unique habitat type would have its own binary column.\n",
    "If habitat is ordinal (order matters): One option is ordinal encoding, which assigns numerical values to the categories while preserving the inherent order (e.g., 1 - freshwater, 2 - saltwater, 3 - terrestrial). However, this only works well if the order truly reflects a gradient or relationship between the categories.\n",
    "Diet: Similar to habitat, diet could be categorical (e.g., carnivore, herbivore, omnivore) or ordinal (e.g., herbivore, omnivore, carnivore). Apply the same logic as for habitat:\n",
    "\n",
    "Categorical diet: Use nominal encoding for separate binary columns representing each diet type.\n",
    "Ordinal diet (if order is meaningful): Ordinal encoding could be used, assigning values like 1 - herbivore, 2 - omnivore, 3 - carnivore.\n",
    "Justification:\n",
    "\n",
    "Nominal encoding is well-suited for both species and categorical habitat/diet because it doesn't make assumptions about order between the categories. This aligns well with the real-world understanding of these features (e.g., being a carnivore isn't inherently better or worse than being an herbivore).\n",
    "For ordinal habitat/diet, we can consider ordinal encoding if the order reflects a meaningful relationship. However, it's crucial to assess if the order truly matters in the context of the specific problem. Nominal encoding might still be a good alternative for these features as well.\n",
    "By carefully considering the nature of the categorical data (ordered or not), we can choose the most appropriate encoding technique to accurately represent the information for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91947f4d-bdf4-4f9d-bd40-7c7423744bf4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "82e3390b-7278-4799-8581-6f65e93fa13e",
   "metadata": {},
   "source": [
    "Q7.You are working on a project that involves predicting customer churn for a telecommunications\n",
    "company. You have a dataset with 5 features, including the customer's gender, age, contract type,\n",
    "monthly charges, and tenure. Which encoding technique(s) would you use to transform the categorical\n",
    "data into numerical data? Provide a step-by-step explanation of how you would implement the encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b39891c-dc32-4e60-9cbd-35fad1540b27",
   "metadata": {},
   "source": [
    "Certainly! Here's how you can transform the categorical data into numerical data for your customer churn prediction project:\n",
    "\n",
    "Encoding Techniques:\n",
    "\n",
    "Gender: This is a categorical feature with no inherent order (male/female).  We can use nominal encoding (one-hot encoding) to create separate binary columns for \"male\" and \"female.\"\n",
    "\n",
    "Contract Type: This is also a categorical feature with no assumed order (e.g., monthly, biannual, annual). Nominal encoding is again suitable. You'll create individual binary columns for each unique contract type.\n",
    "\n",
    "Implementation Steps (using Python's pandas library):\n",
    "\n",
    "Import libraries and Load Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aae145ca-ef21-4f19-9f29-5e28cbb38e71",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'churn_data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Assuming you have your data in a CSV file named 'churn_data.csv'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchurn_data.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'churn_data.csv'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd63e994-57a1-4386-a921-864414d274b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
